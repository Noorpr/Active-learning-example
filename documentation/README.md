# ğŸ“ Faculty of Computer and Artificial Intelligence â€“ Cairo University

## ğŸ“˜ Assignment: Active Learning Strategies

---

ğŸ‘¤ **Name:** Noor Elden Tariq Mohammed Medhat  
ğŸ“… **Academic Year:** 2024â€“2025

---

## ğŸ“‘ Table of Contents

1. [ğŸ“– Introduction](#-introduction)  
2. [âš–ï¸ Active vs. Passive Learning](#-active-vs-passive-learning)  
3. [ğŸ“Š Datasets](#-datasets)  
4. [ğŸ§  Strategies](#-strategies)  
5. [ğŸ”¬ Experiments (Methodology)](#-experiments-methodology)  
6. [ğŸ“ˆ Results](#-results)  
7. [âœ… Conclusion](#-conclusion)  
8. [ğŸ”— References](#-references)

---

## ğŸ“– Introduction

Active learning is a machine learning technique where the model chooses the data it learns from. Instead of training on a fully labeled dataset, the model selects the most **informative or uncertain samples** to be labeled by a human (oracle).  
This reduces labeling costs while still achieving **high accuracy**.

ğŸ“Œ Common in:  
- ğŸ–¼ï¸ Image classification  
- ğŸ“š NLP  
- ğŸ¥ Medical diagnosis

---

## âš–ï¸ Active vs Passive Learning

| ğŸ” Active Learning                         | ğŸ“¥ Passive Learning                        |
|-------------------------------------------|--------------------------------------------|
| Chooses what data to learn from           | Uses all labeled data                      |
| Focuses on uncertain or informative cases | No selection or prioritization             |
| More efficient with fewer labeled samples | May require more labeled data              |

---

## ğŸ“Š Datasets

### ğŸ©º Breast Cancer Dataset
- Features from digitized images of **breast masses**
- Classes: **Malignant** or **Benign**
- âš ï¸ Imbalanced dataset â†’ needs careful handling

### ğŸŒ¸ Iris Dataset
- Classic dataset with **150 flower samples**
- 3 Species: Setosa, Versicolor, Virginica  
- Balanced: 50 samples per class  
- 4 features per sample:  
  - Sepal Length, Sepal Width  
  - Petal Length, Petal Width

---

## ğŸ§  Strategies

### ğŸ”» Uncertainty Sampling
- Picks samples where prediction confidence is **lowest**
- E.g., predicted probability close to 0.5  
- Boosts learning by targeting confusion points

### ğŸ§‘â€âš–ï¸ Query by Committee (QBC)
- Trains multiple models (a **committee**)  
- Selects samples with **most disagreement**  
- More diverse insights â†’ better decision boundary

### ğŸ¯ Expected Error Sampling
- Predicts which sample would most reduce future model error  
- Selects based on **expected improvement** in accuracy

---

## ğŸ”¬ Experiments (Methodology)

### Initial Training
- Train models on a small initial labeled dataset.
- Establish baseline performance metrics.

### Active Selection
- Apply different strategies to select informative samples.
- Request labels for the selected data points.

### Model Updating
- Retrain models with newly labeled data.
- Evaluate performance improvements after each iteration.

---

## ğŸ“ˆ Results

### Query by Committee (QBC)

![QBC - Breast Cancer](QBC-BreastCancer.png)

The plot above illustrates the progress of model accuracy using the Query by Committee strategy over 20 queries. Initially, the accuracy fluctuates around 0.90, indicating some instability as the model learns from the selected samples. However, after about 10 queries, there is a noticeable improvement, with accuracy peaking at over 0.94. This suggests that the strategy effectively identifies informative samples, leading to significant performance gains. The slight dips in accuracy highlight the ongoing challenge of selecting the most beneficial data points, but overall, the trend is positive.
